{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "    1. Make sure everyone has the necesary programs:\n",
    "         - Pyhton\n",
    "         - Jupyter\n",
    "         - Github\n",
    "    2. Intro tp Git\n",
    "    3. Clone Titanic book\n",
    "    4. Start cleaning data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 basic steps to Machine Learning:\n",
    "#### 1. Data gathering/cleaning/feature development\n",
    "     2. Model Selection\n",
    "     3. Fitting the model\n",
    "     4. Make predicitons\n",
    "     5. Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#just sticking with Pandas today to manipulate and clean the Titanic dataset \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you will need to map to where your files are located \n",
    "train = pd.read_csv(######train.csv')\n",
    "test = pd.read_csv(#######test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# created a dataframe to hold passenger ID and eventually our submission \n",
    "Submission = pd.DataFrame()\n",
    "Submission['PassengerId'] = test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are going to remove the target (survived) from train and combine train and test so that are feature is consistent\n",
    "# must be careful when doing this to not drop rows from either set during cleaning\n",
    "y = train.Survived\n",
    "combined = pd.concat([train.drop(['Survived'], axis=1),test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to go through each feature one by one and develop our final train and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger ID is just an incremented count of passengers, no value so lets drop it\n",
    "\n",
    "combined = combined.drop('PassengerId', axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# at first glance Name appears to have no value, but notice the title within the name ex. Mrs, Mr, Master, etc\n",
    "# these may be valuable as it may signify crew or socioeconomic class \n",
    "# We need to split out the Title within the Name columnm, we can name it Title\n",
    "combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "# and we can drop Name\n",
    "combined = combined.drop('Name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one last action to perform on the Name or now Title, we need to create dummy variables so our value is numeric\n",
    "combined = pd.get_dummies(combined, columns=['Title'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and we must do the same thing to Sex\n",
    "combined = pd.get_dummies(combined, columns=['Sex'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overall age is fine but we are missing values, we need 1309 and we only have 1046. We will do a simple imputation \n",
    "# We are also missing 1 fare value, and 2 Embarked values\n",
    "# We will do a slightly different imputation for each\n",
    "\n",
    "combined['Age'] = combined.Age.fillna(combined.Age.mean())\n",
    "combined['Fare'] = combined.Fare.fillna(combined.Age.median())\n",
    "combined['Embarked'] = combined.Embarked.fillna(combined.Embarked.ffill())\n",
    "\n",
    "# and we need to create dummy variables for embarked\n",
    "combined = pd.get_dummies(combined, columns=['Embarked'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just have ticket and cabin left\n",
    "# lets first look at the first 20 tickets and see if there may be any value there:\n",
    "\n",
    "combined.Ticket[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there doesn't appear to be anything worth extracting so let's drop Ticket\n",
    "combined = combined.drop('Ticket', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we are left with cabin, lets take a look at the first 50\n",
    "combined.Cabin[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# looks like there are a lot of missing values, but they might mean they didn't have a cabin and the significance of A, B, C\n",
    "# might be something of value.  Let's parse it out and assign the NAN a U for unknown\n",
    "\n",
    "combined['Cabin'] = combined.Cabin.fillna('U')\n",
    "combined['Cabin'] = combined['Cabin'].map(lambda c : c[0])\n",
    "\n",
    "# Finally apply dummy variables to Cabin\n",
    "combined = pd.get_dummies(combined, columns=['Cabin'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are good to go.  No missing values and everthing is numeric\n",
    "# lets put the test and train set back together\n",
    "\n",
    "# remebering the length of the train set\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combined.iloc[:891]\n",
    "test = combined.iloc[891:]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will pick up from here at our next meeting with model selction and introduction to pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.values\n",
    "X_test = test.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Submission['Survived'] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you need to map the submission file to your computer \n",
    "Submission.to_csv(##submission.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
